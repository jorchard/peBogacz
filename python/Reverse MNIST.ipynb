{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "import NeuralNetwork as NN\n",
    "import Layer\n",
    "import importlib\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from IPython.display import display\n",
    "from ipywidgets import FloatProgress\n",
    "\n",
    "import mnist_loader\n",
    "importlib.reload(mnist_loader)\n",
    "importlib.reload(NN)\n",
    "importlib.reload(Layer);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "howmany = -1 #50\n",
    "train, validate, test = mnist_loader.load_data_wrapper()\n",
    "train = [torch.tensor(train[0][:howmany]).float().to(device), torch.tensor(train[1][:howmany]).float().to(device)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reversed\n",
    "net = NN.NeuralNetwork()\n",
    "net.AddLayer(Layer.InputPELayer(n=10))  # 0 Class vector\n",
    "net.AddLayer(Layer.TopPELayer(n=784))  # 1 Input\n",
    "net.Connect(0,1)\n",
    "# Input layer is one-hot\n",
    "net.layers[0].sigma = Layer.softmax\n",
    "net.layers[0].sigma_p = Layer.softmax_p\n",
    "# Top vector reconstructed image, [0, 1]\n",
    "net.layers[1].sigma = Layer.logistic\n",
    "net.layers[1].sigma_p = Layer.logistic_p\n",
    "\n",
    "net.SetTau(0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.layers[0].Probe(True)\n",
    "net.layers[1].Probe(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc5603f27ac47aea3a739701f2abebd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1431.1544585227966\n"
     ]
    }
   ],
   "source": [
    "# Train in reverse direction: one-hot -> reconstructed image\n",
    "epochs = 10\n",
    "T = 3.\n",
    "dt = 0.01\n",
    "start_time = time.time()\n",
    "batch_size = 100\n",
    "net.learning_tau = torch.tensor(batch_size).float().to(device) * 5.\n",
    "fp = FloatProgress(min=0,max=epochs*len(train[0]))  \n",
    "display(fp)\n",
    "for k in range(epochs):\n",
    "    batches = NN.MakeBatches(train[1], train[0], batch_size=batch_size)\n",
    "    for x in batches:\n",
    "        #net.Reset()\n",
    "        net.Infer(T, x[0], x[1], dt=dt)\n",
    "        fp.value += batch_size\n",
    "end_time = time.time()\n",
    "print('Total time: '+str(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.1887e-02,  4.1694e-02,  3.4956e-02,  ...,  3.8796e-02,\n",
       "          5.2357e-02,  4.5017e-02],\n",
       "        [ 6.0329e-02,  3.9612e-02,  3.2366e-02,  ...,  4.9484e-02,\n",
       "          5.5642e-02,  5.5912e-02],\n",
       "        [-1.1934e-02, -2.6679e-02, -2.2368e-02,  ..., -1.3010e-02,\n",
       "         -1.9315e-02, -2.1777e-02],\n",
       "        ...,\n",
       "        [-2.4175e-02, -3.9349e-02, -3.9757e-02,  ..., -4.5676e-02,\n",
       "         -3.5950e-02, -4.4775e-02],\n",
       "        [-1.9169e-02, -1.5776e-02, -1.6090e-02,  ..., -1.5669e-02,\n",
       "         -1.4056e-02, -2.3180e-03],\n",
       "        [-2.5370e-03, -5.9846e-03,  1.3149e-02,  ..., -4.7618e-03,\n",
       "         -1.0428e-02, -2.4019e-02]], device='cuda:0')"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.connections[0].W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probe the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = net.Predict(10., train[1][0], dt=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-314-1b2e7b0fec9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "plt.plot(net.t_history, np.array(net.layers[1].v_history)[:,200:300]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.Save('MNIST reversed.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1463,  0.0790,  0.0497,  0.0784,  0.0228, -0.0949, -0.1570,\n",
      "         0.8602, -0.1136,  0.1532], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABM5JREFUeJzt3S1uVV0UgOGetgIJIUgSMAyBCaCqWhwJTABNggTPJMA2\nKNIhVNYUicCQQDoCHD0IDJ+4m5+v957S93nsuidnpeHNFpvbTvM8bwE920svACxD/BAlfogSP0SJ\nH6LED1HihyjxQ5T4IWp3ky+bpsl/J4Q1m+d5+p3POfkhSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK\n/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+i\nxA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPgh\nSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6J2l17gZzdv3hzOnzx5snJ29+7di16H\nra2tr1+/DucnJyfD+fv37y9ynf949uzZcP706dOVs+1t556fAESJH6LED1HihyjxQ5T4IUr8EDXN\n87y5l03T8GUfP34cPn/nzp2LXOfKGN1Zn5+fb3CTf8fOzs7SK6zNPM/T73zOyQ9R4oco8UOU+CFK\n/BAlfogSP0Rdqu/z7+/vL71CzuPHj4fzX/2OhXW++9q1a8P5p0+fhvNXr1798U4lTn6IEj9EiR+i\nxA9R4oco8UOU+CHqUn2fn5aXL18O5y9evBjOj46OhvODg4M/3ukq8H1+YEj8ECV+iBI/RIkfosQP\nUZfqK720PHjwYOkV0pz8ECV+iBI/RIkfosQPUeKHKPFDlHt+FnPv3r3/9fzh4eEFbdLk5Ico8UOU\n+CFK/BAlfogSP0SJH6Lc8/PPOjs7W3qFf5qTH6LED1HihyjxQ5T4IUr8ECV+iHLPz1pdv3595Wx3\nd/zP7/Pnz8P5hw8f/monfnDyQ5T4IUr8ECV+iBI/RIkfosQPUe75Wau9vb2Vsxs3bgyf/dU9/5cv\nX/5qJ35w8kOU+CFK/BAlfogSP0SJH6Jc9XFpnZ6eLr3ClebkhyjxQ5T4IUr8ECV+iBI/RIkfotzz\ns5jt7fHZc3x8vKFNmpz8ECV+iBI/RIkfosQPUeKHKPFDlHt+1ur27dsrZ+fn58Nn53m+6HX4iZMf\nosQPUeKHKPFDlPghSvwQJX6Ics/PWj18+HDpFVjByQ9R4oco8UOU+CFK/BAlfogSP0SJH6LED1Hi\nhyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAl\nfojyJ7pZq5OTk5Wz+/fvD5/91fzNmzfD+bdv34bzOic/RIkfosQPUeKHKPFDlPghSvwQNc3zvLmX\nTdPmXsalsLe3t3L27t274bM7OzvD+aNHj4bzt2/fDudX1TzP0+98zskPUeKHKPFDlPghSvwQJX6I\nctXHYs7OzobzW7duDedHR0fD+cHBwR/vdBW46gOGxA9R4oco8UOU+CFK/BAlfojyq7tZzOvXr4fz\n58+fD+enp6cXuU6Okx+ixA9R4oco8UOU+CFK/BAlfoja6Pf5gcvDyQ9R4oco8UOU+CFK/BAlfogS\nP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EfQfVa3+fTu8d\npwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b3af59278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = 147 #147 or 35   for 2s\n",
    "p = 141 #133 or 141   for 7s\n",
    "plt.imshow(np.reshape(test[0][p],[28,28]), cmap='gray'); plt.axis('off');\n",
    "net.Reset()\n",
    "net.SetTau(0.04)\n",
    "z = net.Generate(3., test[0][p])\n",
    "y = net.layers[1].sigma(z)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQCjCD4Qi/EAowg+EIvxAqP8AT3yk5KmFygkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b50f9b5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net.Reset()\n",
    "z = net.Predict(3., test[1][p])\n",
    "plt.imshow(np.reshape(z,[28, 28]), cmap='gray'); plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "indata = test[0][200:300]\n",
    "outdata = test[1][200:300]\n",
    "x = net.Generate(5., indata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array(deepcopy(x))\n",
    "for idx, blah in enumerate(x):\n",
    "    z[idx,:] = NN.OneHot(blah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 85.0%\n"
     ]
    }
   ],
   "source": [
    "err = np.sum(np.abs(z-outdata))/2.\n",
    "print('Accuracy = '+str((len(z)-err)/len(z)*100.)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1., -1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0., -1.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1., -1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0., -1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., -1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., -1.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., -1.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z-outdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.OneHot(blah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.], device='cuda:0')"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
