{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Classification\n",
    "Under construction (3 Oct 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "dtype = torch.float\n",
    "import NeuralNetwork as NN\n",
    "import Layer\n",
    "import importlib\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from IPython.display import display\n",
    "from ipywidgets import FloatProgress\n",
    "\n",
    "importlib.reload(NN)\n",
    "importlib.reload(Layer);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MakeBatches(data_in, data_out, batch_size=10):\n",
    "    '''\n",
    "    batches = MakeBatches(data_in, data_out, batch_size=10)\n",
    "    \n",
    "    Breaks up the dataset into batches of size batch_size.\n",
    "    \n",
    "    Inputs:\n",
    "      data_in    is a list of inputs\n",
    "      data_out   is a list of outputs\n",
    "      batch_size is the number of samples in each batch\n",
    "      \n",
    "    Output:\n",
    "      batches is a list containing batches, where each batch is:\n",
    "                 [in_batch, out_batch]\n",
    "    '''\n",
    "    N = len(data_in)\n",
    "    batches = []\n",
    "    for k in range(0, N, batch_size):\n",
    "        din = data_in[k:k+batch_size]\n",
    "        dout = data_out[k:k+batch_size]\n",
    "        if isinstance(din, (list, tuple)):\n",
    "            batches.append( [torch.stack(din, dim=0).float().to(device) , torch.stack(dout, dim=0).float().to(device)] )\n",
    "        else:\n",
    "            batches.append( [din.float().to(device) , dout.float().to(device)] )\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Binary one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1 -1 -1  1  1 -1] -> [1. 0. 0. 0. 0.]\n",
      "[-1  1 -1  1 -1  1 -1  1] -> [0. 1. 0. 0. 0.]\n",
      "[-1  1  1 -1  1 -1 -1  1] -> [0. 0. 1. 0. 0.]\n",
      "[ 1 -1 -1 -1  1 -1  1  1] -> [0. 0. 0. 1. 0.]\n",
      "[ 1 -1 -1  1 -1  1 -1  1] -> [0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 8->5 binary one-hot\n",
    "noise = 0.\n",
    "n_samples = 100\n",
    "s = np.array([[1,0,1,0,0,1,1,0],\n",
    "                         [0,1,0,1,0,1,0,1],\n",
    "                         [0,1,1,0,1,0,0,1],\n",
    "                         [1,0,0,0,1,0,1,1],\n",
    "                         [1,0,0,1,0,1,0,1]], dtype=float)\n",
    "e = np.eye(5)\n",
    "s = s*2. - 1.\n",
    "#e = e*2. - 1.\n",
    "classes = len(s)\n",
    "training_input = []\n",
    "training_output = []\n",
    "r = 0\n",
    "for n in range(n_samples):\n",
    "    training_input.append(np.array(s[r], dtype=float) + noise*np.random.normal(scale=0.01,size=len(s[r])))\n",
    "    training_output.append(np.array(e[r], dtype=float))\n",
    "    r = np.mod(r+1, classes) #r = np.random.randint(classes)\n",
    "\n",
    "training_input = torch.tensor(training_input).float().to(device)\n",
    "training_output = torch.tensor(training_output).float().to(device)\n",
    "train = [training_input, training_output]\n",
    "\n",
    "n_test_samples = 100\n",
    "test_input = []\n",
    "test_output = []\n",
    "r = 0\n",
    "for n in range(n_test_samples):\n",
    "    test_input.append(np.array(s[r], dtype=float) + noise*np.random.normal(scale=0.01,size=len(s[r])))\n",
    "    test_output.append(np.array(e[r], dtype=float))\n",
    "    r = np.mod(r+1, classes) #np.random.randint(classes)\n",
    "\n",
    "test_input = torch.tensor(test_input).float().to(device)\n",
    "test_output = torch.tensor(test_output).float().to(device)\n",
    "test = [test_input, test_output]\n",
    "\n",
    "for x, t in zip(s,e):\n",
    "    print(str(np.array(x,dtype=int))+' -> '+str(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'NeuralNetwork' from '/Users/jorchard/Dropbox/research/peBogacz/python/NeuralNetwork.py'>"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(Layer)\n",
    "importlib.reload(NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "net = NN.NeuralNetwork()\n",
    "net.AddLayer(Layer.InputPELayer(n=8))\n",
    "net.AddLayer(Layer.PELayer(n=7))\n",
    "net.Connect(0, 1)\n",
    "net.AddLayer(Layer.PELayer(n=6))\n",
    "net.Connect(1,2)\n",
    "net.AddLayer(Layer.TopPELayer(n=5))\n",
    "net.Connect(2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Binary Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1 -1 -1  1  1 -1] -> [-1.  1.  1.  1.]\n",
      "[-1  1 -1  1 -1  1 -1  1] -> [ 1.  1. -1.  1.]\n",
      "[-1  1  1 -1  1 -1 -1  1] -> [ 1. -1.  1.  1.]\n",
      "[ 1 -1 -1 -1  1 -1  1  1] -> [ 1.  1.  1. -1.]\n",
      "[ 1 -1 -1  1 -1  1 -1  1] -> [-1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# 8->4 binary mapping\n",
    "noise = 0.\n",
    "n_samples = 100\n",
    "s = np.array([[1,0,1,0,0,1,1,0],\n",
    "                         [0,1,0,1,0,1,0,1],\n",
    "                         [0,1,1,0,1,0,0,1],\n",
    "                         [1,0,0,0,1,0,1,1],\n",
    "                         [1,0,0,1,0,1,0,1]], dtype=float)\n",
    "e = np.array([[0,1,1,1],[1,1,0,1],[1,0,1,1],[1,1,1,0],[0,0,0,0]])\n",
    "s = s*2. - 1.\n",
    "e = e*2. - 1.\n",
    "classes = len(s)\n",
    "training_input = []\n",
    "training_output = []\n",
    "r = 0\n",
    "for n in range(n_samples):\n",
    "    r = np.mod(r+1, classes) #r = np.random.randint(classes)\n",
    "    training_input.append(np.array(s[r], dtype=float) + noise*np.random.normal(scale=0.01,size=len(s[r])))\n",
    "    training_output.append(np.array(e[r], dtype=float))\n",
    "\n",
    "training_input = torch.tensor(training_input).float().to(device)\n",
    "training_output = torch.tensor(training_output).float().to(device)\n",
    "train = [training_input, training_output]\n",
    "\n",
    "n_test_samples = 100\n",
    "test_input = []\n",
    "test_output = []\n",
    "r = 0\n",
    "for n in range(n_test_samples):\n",
    "    r = np.mod(r+1, classes) #np.random.randint(classes)\n",
    "    test_input.append(np.array(s[r], dtype=float) + noise*np.random.normal(scale=0.01,size=len(s[r])))\n",
    "    test_output.append(np.array(e[r], dtype=float))\n",
    "\n",
    "test_input = torch.tensor(test_input).float().to(device)\n",
    "test_output = torch.tensor(test_output).float().to(device)\n",
    "test = [test_input, test_output]\n",
    "\n",
    "for x, t in zip(s,e):\n",
    "    print(str(np.array(x,dtype=int))+' -> '+str(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "net = NN.NeuralNetwork()\n",
    "net.AddLayer(Layer.InputPELayer(n=8))\n",
    "# net.AddLayer(Layer.PELayer(n=7))\n",
    "# net.Connect(0, 1)\n",
    "# net.AddLayer(Layer.PELayer(n=6))\n",
    "# net.Connect(1,2)\n",
    "# net.AddLayer(Layer.TopPELayer(n=4))\n",
    "# net.Connect(2,3)\n",
    "# net.ConnectNextLayer(Layer.InputPELayer(n=8))\n",
    "net.ConnectNextLayer(Layer.PELayer(n=7))\n",
    "net.ConnectNextLayer(Layer.PELayer(n=6))\n",
    "net.ConnectNextLayer(Layer.TopPELayer(n=4))\n",
    "net.layers[-1].sigma = Layer.tanh\n",
    "net.layers[-1].sigma_p = Layer.tanh_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Layer.tanh>"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[-1].sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polar Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.25 -0.6 ]\n",
      " [ 0.   -0.6 ]\n",
      " [ 0.25 -0.6 ]\n",
      " [-0.25 -0.2 ]\n",
      " [ 0.   -0.2 ]\n",
      " [ 0.25 -0.2 ]\n",
      " [-0.25  0.2 ]\n",
      " [ 0.    0.2 ]\n",
      " [ 0.25  0.2 ]\n",
      " [-0.25  0.6 ]\n",
      " [ 0.    0.6 ]\n",
      " [ 0.25  0.6 ]]\n",
      "[[-0.07725425 -0.23776413]\n",
      " [-0.1545085  -0.47552826]\n",
      " [-0.23176275 -0.71329239]\n",
      " [ 0.20225425 -0.14694631]\n",
      " [ 0.4045085  -0.29389263]\n",
      " [ 0.60676275 -0.44083894]\n",
      " [ 0.20225425  0.14694631]\n",
      " [ 0.4045085   0.29389263]\n",
      " [ 0.60676275  0.44083894]\n",
      " [-0.07725425  0.23776413]\n",
      " [-0.1545085   0.47552826]\n",
      " [-0.23176275  0.71329239]]\n"
     ]
    }
   ],
   "source": [
    "n_theta = 4\n",
    "n_rho = 3\n",
    "s = []\n",
    "e = []\n",
    "#for theta in np.linspace(2.*np.pi/(n_theta+2.), 2.*np.pi*(n_theta+1.)/(n_theta+2.), n_theta, endpoint=True):\n",
    "for theta in np.linspace(-1., 1, n_theta+1, endpoint=False):\n",
    "    if theta != -1.:\n",
    "        theta_radians = theta*np.pi\n",
    "        for rho in np.linspace(0., 1., n_rho+1, endpoint=False):\n",
    "            if rho != 0.:\n",
    "                rho2 = rho - 0.5\n",
    "                e.append([rho2, theta])\n",
    "                x = rho*np.cos(theta_radians)\n",
    "                y = rho*np.sin(theta_radians)\n",
    "                s.append([x,y])\n",
    "e = np.array(e)\n",
    "s = np.array(s)\n",
    "print(e)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_samples = 100\n",
    "r = 0\n",
    "training_input = []\n",
    "training_output = []\n",
    "for n in range(training_samples):\n",
    "    r = np.mod(r+1, len(s)) #r = np.random.randint(classes)\n",
    "    training_input.append(np.array(s[r,:], dtype=float) )#+ noise*np.random.normal(scale=0.01,size=len(s[r,:])))\n",
    "    training_output.append(np.array(e[r,:], dtype=float))\n",
    "\n",
    "training_input = torch.tensor(training_input).float().to(device)\n",
    "training_output = torch.tensor(training_output).float().to(device)\n",
    "train = [training_input, training_output]\n",
    "\n",
    "n_test_samples = 100\n",
    "test_input = []\n",
    "test_output = []\n",
    "r = 0\n",
    "for n in range(n_test_samples):\n",
    "    r = np.mod(r+1, len(s)) #r = np.random.randint(classes)\n",
    "    test_input.append(np.array(s[r,:], dtype=float) )#+ noise*np.random.normal(scale=0.01,size=len(s[r,:])))\n",
    "    test_output.append(np.array(e[r,:], dtype=float))\n",
    "\n",
    "test_input = torch.tensor(test_input).float().to(device)\n",
    "test_output = torch.tensor(test_output).float().to(device)\n",
    "test = [test_input, test_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAC7CAYAAABhEzkiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11153ccc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1); plt.plot(s[:,0], s[:,1], 'b.'); plt.axis('square');\n",
    "plt.subplot(1,2,2); plt.plot(e[:,0], e[:,1], 'b.'); plt.axis('square');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = NN.NeuralNetwork()\n",
    "net.AddLayer(Layer.InputPELayer(n=2)) # 0\n",
    "net.AddLayer(Layer.PELayer(n=6))      # 1\n",
    "net.AddLayer(Layer.PELayer(n=8))      # 2\n",
    "net.AddLayer(Layer.TopPELayer(n=10))  # 3 (augmented)\n",
    "net.AddLayer(Layer.TopPELayer(n=2))   # 4\n",
    "net.Connect(0,1)\n",
    "net.Connect(1,2)\n",
    "net.Connect(2,3)\n",
    "net.Connect(2,4)\n",
    "net.layers[3].sigma = Layer.tanh\n",
    "net.layers[3].sigma_p = Layer.tanh_p\n",
    "net.layers[3].SetFF()  # Augmenting layers have no upper input\n",
    "net.layers[4].sigma = Layer.tanh\n",
    "net.layers[4].sigma_p = Layer.tanh_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = NN.NeuralNetwork()\n",
    "net.AddLayer(Layer.InputPELayer(n=2)) # 0\n",
    "net.AddLayer(Layer.PELayer(n=50))     # 1\n",
    "net.AddLayer(Layer.PELayer(n=50))     # 2\n",
    "net.AddLayer(Layer.TopPELayer(n=2))   # 3\n",
    "net.Connect(0,1)\n",
    "net.Connect(1,2)\n",
    "net.Connect(2,3)\n",
    "net.layers[3].sigma = Layer.tanh\n",
    "net.layers[3].sigma_p = Layer.tanh_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae18a1c8aae4d4e8c65de549858937b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 43.10140609741211\n"
     ]
    }
   ],
   "source": [
    "train_shuffle = list(zip(train[0],train[1]))\n",
    "net.learning_tau = 100.\n",
    "batch_size = 10\n",
    "epochs = 40\n",
    "fp = FloatProgress(min=0,max=epochs*len(train_shuffle))\n",
    "display(fp)\n",
    "T = 3\n",
    "start_time = time.time()\n",
    "for k in range(epochs):\n",
    "    np.random.shuffle(train_shuffle)\n",
    "    unzip = list(zip(*train_shuffle))\n",
    "    batches = MakeBatches(unzip[0], unzip[1], batch_size)\n",
    "    for x in batches:\n",
    "        net.Reset()\n",
    "        net.Infer(T, x[0], x[1])\n",
    "        fp.value += batch_size\n",
    "end_time = time.time()\n",
    "print('Total time: '+str(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.Save('blah.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.Reset()\n",
    "yy = net.Predict(10., train[0])\n",
    "y_true = train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9530, -0.8860],\n",
      "        [-0.9580, -0.8740],\n",
      "        [ 0.3320, -0.8610],\n",
      "        [ 0.9540, -0.9010],\n",
      "        [ 0.9800, -0.8660],\n",
      "        [ 0.9750,  0.6930],\n",
      "        [ 0.9830,  0.9060],\n",
      "        [ 0.9860,  0.8160],\n",
      "        [ 0.7240,  0.8950],\n",
      "        [-0.8000,  0.8230]])\n",
      "tensor([[ 0.0000, -0.6000],\n",
      "        [ 0.2500, -0.6000],\n",
      "        [-0.2500, -0.2000],\n",
      "        [ 0.0000, -0.2000],\n",
      "        [ 0.2500, -0.2000],\n",
      "        [-0.2500,  0.2000],\n",
      "        [ 0.0000,  0.2000],\n",
      "        [ 0.2500,  0.2000],\n",
      "        [-0.2500,  0.6000],\n",
      "        [ 0.0000,  0.6000]])\n"
     ]
    }
   ],
   "source": [
    "print(np.round(yy[:10],decimals=3))\n",
    "print(y_true[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.Reset()\n",
    "yy = net.Generate(10., test[1])\n",
    "y_true = test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Test for binary strings dataset\n",
    "fail = 0\n",
    "for x,t in zip(yy, y_true):\n",
    "    if np.isnan(t).any() or torch.min(x*t).le(0.):\n",
    "        fail += 1\n",
    "n_trials = float(len(y_true))\n",
    "print('Accuracy '+str((n_trials-fail)/n_trials*100.)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "# Test for polar clusters dataset\n",
    "fail = 0\n",
    "for x,t in zip(yy, y_true):\n",
    "    if np.isnan(t).any() or torch.max(abs(x-t)).ge(0.2):\n",
    "        fail += 1\n",
    "n_trials = float(len(test[0]))\n",
    "print('Accuracy '+str((n_trials-fail)/n_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1699,  0.1597,  0.1946,  0.3365,  0.1393])\n",
      "tensor([ 0.,  1.,  0.,  0.,  0.])\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(test[0]))\n",
    "net.Reset()\n",
    "print(net.Predict(5., test[0][idx]))\n",
    "print(test[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net2 = NN.NeuralNetwork()\n",
    "net2.Load('blah.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 7])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(net2.W[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([nan., nan., nan., nan., nan.])\n",
      "tensor([ 0.,  1.,  0.,  0.,  0.])\n"
     ]
    }
   ],
   "source": [
    "net2.Reset()\n",
    "print(net2.Predict(5., test[0][idx]))\n",
    "print(test[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7])\n",
      "torch.Size([7, 8])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 7])\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(net2.layers[1].dvdt))\n",
    "print(np.shape(net2.W[0]))\n",
    "print(np.shape(net2.layers[0].e))\n",
    "print(np.shape(net2.M[0]))\n",
    "print(np.shape(net2.layers[1].v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7])\n",
      "torch.Size([7, 8])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 7])\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(net.layers[1].dvdt))\n",
    "print(np.shape(net.W[0]))\n",
    "print(np.shape(net.layers[0].e))\n",
    "print(np.shape(net.M[0]))\n",
    "print(np.shape(net.layers[1].v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5916, -0.5986, -0.8456, -0.7550,  0.8802, -0.8882,  0.5235,\n",
      "         1.1115])\n",
      "tensor([ 1., -1., -1., -1.,  1., -1.,  1.,  1.])\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(test[1]))\n",
    "xx = net.Generate(10., test[1][idx])\n",
    "print(xx)\n",
    "print(test[0][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "print(np.round(x_true[idx:idx+5],0)-np.round(x_est[idx:idx+5],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. -1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9986,  0.9992, -0.9991,  0.9972], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 58\n",
    "print(train[1][idx])\n",
    "net.Predict(10., train[0][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {
    "8136bdaf4a3a4a7a8ebc121258db3244": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "df58eb1fe74745dc82a439a5c68f9390": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
