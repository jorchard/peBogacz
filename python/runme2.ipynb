{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Classification\n",
    "Under construction (3 Oct 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "dtype = torch.float\n",
    "import NeuralNetwork as NN\n",
    "import Layer\n",
    "import importlib\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from IPython.display import display\n",
    "from ipywidgets import FloatProgress\n",
    "\n",
    "importlib.reload(NN)\n",
    "importlib.reload(Layer);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1 -1 -1  1  1 -1] -> [1. 0. 0. 0. 0.]\n",
      "[-1  1 -1  1 -1  1 -1  1] -> [0. 1. 0. 0. 0.]\n",
      "[-1  1  1 -1  1 -1 -1  1] -> [0. 0. 1. 0. 0.]\n",
      "[ 1 -1 -1 -1  1 -1  1  1] -> [0. 0. 0. 1. 0.]\n",
      "[ 1 -1 -1  1 -1  1 -1  1] -> [0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# 8->5 binary one-hot\n",
    "noise = 0.\n",
    "n_samples = 100\n",
    "s = np.array([[1,0,1,0,0,1,1,0],\n",
    "                         [0,1,0,1,0,1,0,1],\n",
    "                         [0,1,1,0,1,0,0,1],\n",
    "                         [1,0,0,0,1,0,1,1],\n",
    "                         [1,0,0,1,0,1,0,1]], dtype=float)\n",
    "e = np.eye(5)\n",
    "s = s*2. - 1.\n",
    "#e = e*2. - 1.\n",
    "classes = len(s)\n",
    "training_input = []\n",
    "training_output = []\n",
    "r = 0\n",
    "for n in range(n_samples):\n",
    "    training_input.append(np.array(s[r], dtype=float) + noise*np.random.normal(scale=0.01,size=len(s[r])))\n",
    "    training_output.append(np.array(e[r], dtype=float))\n",
    "    r = np.mod(r+1, classes) #r = np.random.randint(classes)\n",
    "\n",
    "training_input = torch.tensor(training_input).float().to(device)\n",
    "training_output = torch.tensor(training_output).float().to(device)\n",
    "train = [training_input, training_output]\n",
    "\n",
    "n_test_samples = 100\n",
    "test_input = []\n",
    "test_output = []\n",
    "r = 0\n",
    "for n in range(n_test_samples):\n",
    "    test_input.append(np.array(s[r], dtype=float) + noise*np.random.normal(scale=0.01,size=len(s[r])))\n",
    "    test_output.append(np.array(e[r], dtype=float))\n",
    "    r = np.mod(r+1, classes) #np.random.randint(classes)\n",
    "\n",
    "test_input = torch.tensor(test_input).float().to(device)\n",
    "test_output = torch.tensor(test_output).float().to(device)\n",
    "test = [test_input, test_output]\n",
    "\n",
    "n_rand_samples = 10\n",
    "rand_input = []\n",
    "rand_output = []\n",
    "r = 0\n",
    "for n in range(n_test_samples):\n",
    "    rand_input.append(np.random.rand(len(s[r])))\n",
    "    rand_output.append(np.array(e[r], dtype=float))\n",
    "    r = np.mod(r+1, classes) #np.random.randint(classes)\n",
    "\n",
    "rand_input = torch.tensor(rand_input).float().to(device)\n",
    "rand_output = torch.tensor(rand_output).float().to(device)\n",
    "rand = [rand_input, rand_output]\n",
    "\n",
    "\n",
    "\n",
    "for x, t in zip(s,e):\n",
    "    print(str(np.array(x,dtype=int))+' -> '+str(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1297,  0.0687,  0.5727,  0.2408,  0.7897,  0.0575,  0.4017,\n",
       "          0.2225],\n",
       "        [ 0.4630,  0.8307,  0.7560,  0.8344,  0.6730,  0.7848,  0.7565,\n",
       "          0.6031],\n",
       "        [ 0.0172,  0.8904,  0.4537,  0.7306,  0.4877,  0.7032,  0.2875,\n",
       "          0.5797],\n",
       "        [ 0.6168,  0.3560,  0.8856,  0.0699,  0.9765,  0.5857,  0.5256,\n",
       "          0.4325],\n",
       "        [ 0.8697,  0.4211,  0.0540,  0.0592,  0.5751,  0.3790,  0.2890,\n",
       "          0.4161],\n",
       "        [ 0.3456,  0.5062,  0.6144,  0.5458,  0.6651,  0.5052,  0.8863,\n",
       "          0.3154],\n",
       "        [ 0.8693,  0.0144,  0.8416,  0.7145,  0.3437,  0.6773,  0.0133,\n",
       "          0.1711],\n",
       "        [ 0.8862,  0.2896,  0.2165,  0.5244,  0.1474,  0.7182,  0.7175,\n",
       "          0.3526],\n",
       "        [ 0.9882,  0.1726,  0.5613,  0.9507,  0.7037,  0.5910,  0.3358,\n",
       "          0.8675],\n",
       "        [ 0.0232,  0.7638,  0.6825,  0.2982,  0.6172,  0.8474,  0.4510,\n",
       "          0.0556],\n",
       "        [ 0.9026,  0.1886,  0.4705,  0.9290,  0.0662,  0.7404,  0.5321,\n",
       "          0.9720],\n",
       "        [ 0.7477,  0.2898,  0.8714,  0.7970,  0.8373,  0.5811,  0.3876,\n",
       "          0.7504],\n",
       "        [ 0.5306,  0.3572,  0.1881,  0.6036,  0.7838,  0.4145,  0.4571,\n",
       "          0.5617],\n",
       "        [ 0.8482,  0.3062,  0.4653,  0.9031,  0.6053,  0.1219,  0.3005,\n",
       "          0.3044],\n",
       "        [ 0.3815,  0.8009,  0.9554,  0.7668,  0.7052,  0.1055,  0.2393,\n",
       "          0.5804],\n",
       "        [ 0.8681,  0.2203,  0.9311,  0.9395,  0.6073,  0.9356,  0.8980,\n",
       "          0.7374],\n",
       "        [ 0.5263,  0.1879,  0.9451,  0.8833,  0.2220,  0.0310,  0.8007,\n",
       "          0.0665],\n",
       "        [ 0.0628,  0.3848,  0.6397,  0.8120,  0.7007,  0.0387,  0.1730,\n",
       "          0.3661],\n",
       "        [ 0.9982,  0.5585,  0.0109,  0.2876,  0.2947,  0.1153,  0.7336,\n",
       "          0.9783],\n",
       "        [ 0.1989,  0.9084,  0.8398,  0.1390,  0.0003,  0.9205,  0.5006,\n",
       "          0.9267],\n",
       "        [ 0.0988,  0.6883,  0.9963,  0.9735,  0.1420,  0.9276,  0.1560,\n",
       "          0.0434],\n",
       "        [ 0.5718,  0.1543,  0.0129,  0.5824,  0.7288,  0.6872,  0.5879,\n",
       "          0.4417],\n",
       "        [ 0.8523,  0.2108,  0.4789,  0.0393,  0.7185,  0.0239,  0.1215,\n",
       "          0.7723],\n",
       "        [ 0.4788,  0.8369,  0.2099,  0.6978,  0.1957,  0.3800,  0.4400,\n",
       "          0.2675],\n",
       "        [ 0.9378,  0.3854,  0.4432,  0.2935,  0.9427,  0.8517,  0.8816,\n",
       "          0.9148],\n",
       "        [ 0.5583,  0.0428,  0.1586,  0.8738,  0.2511,  0.7729,  0.1987,\n",
       "          0.2752],\n",
       "        [ 0.5106,  0.6989,  0.4298,  0.3356,  0.9488,  0.1226,  0.0976,\n",
       "          0.7527],\n",
       "        [ 0.7458,  0.3444,  0.4230,  0.9417,  0.9652,  0.5083,  0.7278,\n",
       "          0.3177],\n",
       "        [ 0.2173,  0.3295,  0.7495,  0.8367,  0.4550,  0.6247,  0.4256,\n",
       "          0.5316],\n",
       "        [ 0.9523,  0.9466,  0.8379,  0.2101,  0.0613,  0.8119,  0.6668,\n",
       "          0.1369],\n",
       "        [ 0.5369,  0.1944,  0.9122,  0.4131,  0.2795,  0.3586,  0.1286,\n",
       "          0.1325],\n",
       "        [ 0.0178,  0.8328,  0.5354,  0.9667,  0.1279,  0.3829,  0.0561,\n",
       "          0.8886],\n",
       "        [ 0.0615,  0.5521,  0.0486,  0.0327,  0.4018,  0.9766,  0.6557,\n",
       "          0.9144],\n",
       "        [ 0.4686,  0.1538,  0.3142,  0.4077,  0.9199,  0.6316,  0.8129,\n",
       "          0.4041],\n",
       "        [ 0.8548,  0.1803,  0.4252,  0.7185,  0.7796,  0.0921,  0.3250,\n",
       "          0.3882],\n",
       "        [ 0.9423,  0.8933,  0.9193,  0.0130,  0.6831,  0.2072,  0.8476,\n",
       "          0.7154],\n",
       "        [ 0.2714,  0.4007,  0.5119,  0.8052,  0.6065,  0.1227,  0.0145,\n",
       "          0.5953],\n",
       "        [ 0.3712,  0.8737,  0.9586,  0.0207,  0.5127,  0.4173,  0.1682,\n",
       "          0.3590],\n",
       "        [ 0.6219,  0.2244,  0.8280,  0.5612,  0.4356,  0.2473,  0.1983,\n",
       "          0.5629],\n",
       "        [ 0.1583,  0.4727,  0.8475,  0.8442,  0.9299,  0.0245,  0.3171,\n",
       "          0.4743],\n",
       "        [ 0.9105,  0.6787,  0.3477,  0.2569,  0.2561,  0.6618,  0.7313,\n",
       "          0.7411],\n",
       "        [ 0.5507,  0.1521,  0.7175,  0.1925,  0.2642,  0.4362,  0.4241,\n",
       "          0.6699],\n",
       "        [ 0.9189,  0.9963,  0.3258,  0.4700,  0.6421,  0.8530,  0.1075,\n",
       "          0.2685],\n",
       "        [ 0.1953,  0.0834,  0.8002,  0.4504,  0.1213,  0.6096,  0.9085,\n",
       "          0.6995],\n",
       "        [ 0.5494,  0.8820,  0.9080,  0.0985,  0.0753,  0.6488,  0.1396,\n",
       "          0.0100],\n",
       "        [ 0.4584,  0.0412,  0.7068,  0.8843,  0.6549,  0.2282,  0.7557,\n",
       "          0.7969],\n",
       "        [ 0.5836,  0.9869,  0.4518,  0.3032,  0.5704,  0.9457,  0.7863,\n",
       "          0.6383],\n",
       "        [ 0.9850,  0.3921,  0.1207,  0.9153,  0.1448,  0.0751,  0.4171,\n",
       "          0.7829],\n",
       "        [ 0.6893,  0.6148,  0.1511,  0.3800,  0.4366,  0.3300,  0.9279,\n",
       "          0.2712],\n",
       "        [ 0.4950,  0.2332,  0.4502,  0.4083,  0.7925,  0.9672,  0.9080,\n",
       "          0.0561],\n",
       "        [ 0.1717,  0.4809,  0.3717,  0.6076,  0.9120,  0.0383,  0.2823,\n",
       "          0.2927],\n",
       "        [ 0.8002,  0.4346,  0.2976,  0.0366,  0.1175,  0.0788,  0.8108,\n",
       "          0.6546],\n",
       "        [ 0.9342,  0.3462,  0.2555,  0.4969,  0.1304,  0.7983,  0.0088,\n",
       "          0.2250],\n",
       "        [ 0.1647,  0.7854,  0.2672,  0.5550,  0.1968,  0.9443,  0.2322,\n",
       "          0.2612],\n",
       "        [ 0.3540,  0.4015,  0.7337,  0.4166,  0.9126,  0.2229,  0.6140,\n",
       "          0.0144],\n",
       "        [ 0.5647,  0.7003,  0.7502,  0.8725,  0.2761,  0.2360,  0.8175,\n",
       "          0.1658],\n",
       "        [ 0.5986,  0.7279,  0.1372,  0.3702,  0.4992,  0.6677,  0.0781,\n",
       "          0.8518],\n",
       "        [ 0.5964,  0.0883,  0.4328,  0.9622,  0.0351,  0.6885,  0.7896,\n",
       "          0.1169],\n",
       "        [ 0.0360,  0.6586,  0.0409,  0.6603,  0.5895,  0.8517,  0.1938,\n",
       "          0.4762],\n",
       "        [ 0.3402,  0.8385,  0.7483,  0.4255,  0.3333,  0.6896,  0.5859,\n",
       "          0.0423],\n",
       "        [ 0.6819,  0.4895,  0.1229,  0.9589,  0.5521,  0.9747,  0.0411,\n",
       "          0.3824],\n",
       "        [ 0.0026,  0.9527,  0.3150,  0.0784,  0.4866,  0.9734,  0.2343,\n",
       "          0.3774],\n",
       "        [ 0.2967,  0.3536,  0.2408,  0.9514,  0.9038,  0.7280,  0.6133,\n",
       "          0.1991],\n",
       "        [ 0.3695,  0.5182,  0.9347,  0.3303,  0.6500,  0.5012,  0.9368,\n",
       "          0.5117],\n",
       "        [ 0.8719,  0.9086,  0.6834,  0.9922,  0.6244,  0.9122,  0.5829,\n",
       "          0.8415],\n",
       "        [ 0.1812,  0.2285,  0.2044,  0.1825,  0.1704,  0.1456,  0.6998,\n",
       "          0.1563],\n",
       "        [ 0.1242,  0.7473,  0.3727,  0.5240,  0.6697,  0.6809,  0.1939,\n",
       "          0.4683],\n",
       "        [ 0.8920,  0.0304,  0.4024,  0.5163,  0.5206,  0.5063,  0.6686,\n",
       "          0.6515],\n",
       "        [ 0.5094,  0.2107,  0.6451,  0.2736,  0.7702,  0.2647,  0.7440,\n",
       "          0.2777],\n",
       "        [ 0.9719,  0.7671,  0.0240,  0.7318,  0.7481,  0.7038,  0.6334,\n",
       "          0.1128],\n",
       "        [ 0.1046,  0.3039,  0.7634,  0.3643,  0.2897,  0.7805,  0.3443,\n",
       "          0.9631],\n",
       "        [ 0.0531,  0.6868,  0.5314,  0.9523,  0.7863,  0.7515,  0.2453,\n",
       "          0.3226],\n",
       "        [ 0.4966,  0.0370,  0.7833,  0.2505,  0.0334,  0.6911,  0.4961,\n",
       "          0.1552],\n",
       "        [ 0.7918,  0.5686,  0.5496,  0.9241,  0.0529,  0.2538,  0.1786,\n",
       "          0.9801],\n",
       "        [ 0.0274,  0.0551,  0.8836,  0.1404,  0.0016,  0.1646,  0.5684,\n",
       "          0.2129],\n",
       "        [ 0.7867,  0.8282,  0.2748,  0.2298,  0.6571,  0.8956,  0.7816,\n",
       "          0.0770],\n",
       "        [ 0.4688,  0.3672,  0.0843,  0.6269,  0.2853,  0.0958,  0.9792,\n",
       "          0.0354],\n",
       "        [ 0.9861,  0.7934,  0.4642,  0.6440,  0.2254,  0.3808,  0.9059,\n",
       "          0.1698],\n",
       "        [ 0.8764,  0.2803,  0.1453,  0.0531,  0.6558,  0.8825,  0.1824,\n",
       "          0.7006],\n",
       "        [ 0.5334,  0.9642,  0.0997,  0.2693,  0.3364,  0.1173,  0.2008,\n",
       "          0.1717],\n",
       "        [ 0.6188,  0.6968,  0.2687,  0.6397,  0.6808,  0.8780,  0.0486,\n",
       "          0.8447],\n",
       "        [ 0.2845,  0.1998,  0.9965,  0.6255,  0.3308,  0.0276,  0.8246,\n",
       "          0.7087],\n",
       "        [ 0.2841,  0.3825,  0.4054,  0.2526,  0.1856,  0.0016,  0.9314,\n",
       "          0.2312],\n",
       "        [ 0.0133,  0.2912,  0.2880,  0.8844,  0.4731,  0.8133,  0.9421,\n",
       "          0.4424],\n",
       "        [ 0.4722,  0.4710,  0.3028,  0.8025,  0.2544,  0.5671,  0.8696,\n",
       "          0.6510],\n",
       "        [ 0.2215,  0.8825,  0.8187,  0.6432,  0.3262,  0.0581,  0.3111,\n",
       "          0.9903],\n",
       "        [ 0.9268,  0.0912,  0.8845,  0.6614,  0.3577,  0.1776,  0.7913,\n",
       "          0.0748],\n",
       "        [ 0.3133,  0.2751,  0.9388,  0.9432,  0.0614,  0.1253,  0.6750,\n",
       "          0.6926],\n",
       "        [ 0.6884,  0.5298,  0.7703,  0.7472,  0.3224,  0.0967,  0.4285,\n",
       "          0.6675],\n",
       "        [ 0.3403,  0.4118,  0.3656,  0.1684,  0.4803,  0.2949,  0.8798,\n",
       "          0.6202],\n",
       "        [ 0.4710,  0.4717,  0.9977,  0.5708,  0.0660,  0.5074,  0.4655,\n",
       "          0.9224],\n",
       "        [ 0.4123,  0.9535,  0.3312,  0.8248,  0.7643,  0.4472,  0.7158,\n",
       "          0.4929],\n",
       "        [ 0.2723,  0.7536,  0.7500,  0.5668,  0.7334,  0.0218,  0.2811,\n",
       "          0.7804],\n",
       "        [ 0.0704,  0.5947,  0.7990,  0.8063,  0.6422,  0.1408,  0.4265,\n",
       "          0.4099],\n",
       "        [ 0.8235,  0.7708,  0.1471,  0.3341,  0.4850,  0.6444,  0.3365,\n",
       "          0.3666],\n",
       "        [ 0.5686,  0.4147,  0.9448,  0.6156,  0.1576,  0.4516,  0.6886,\n",
       "          0.2718],\n",
       "        [ 0.4689,  0.0184,  0.2594,  0.5783,  0.7670,  0.8344,  0.8364,\n",
       "          0.4041],\n",
       "        [ 0.9536,  0.5134,  0.6965,  0.0714,  0.2242,  0.0599,  0.7378,\n",
       "          0.7094],\n",
       "        [ 0.2209,  0.5549,  0.0797,  0.9444,  0.8326,  0.0791,  0.0634,\n",
       "          0.9898],\n",
       "        [ 0.8953,  0.9889,  0.0134,  0.6061,  0.6203,  0.8010,  0.5859,\n",
       "          0.8379]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = NN.NeuralNetwork()\n",
    "net.AddLayer(Layer.InputPELayer(n=8))\n",
    "net.AddLayer(Layer.PELayer(n=7))\n",
    "net.Connect(0,1)\n",
    "net.AddLayer(Layer.PELayer(n=6))\n",
    "net.Connect(1,2)\n",
    "net.AddLayer(Layer.TopPELayer(n=5))\n",
    "net.Connect(2,3)\n",
    "net.SetTau(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Binary Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1 -1 -1  1  1 -1] -> [-1.  1.  1.  1.]\n",
      "[-1  1 -1  1 -1  1 -1  1] -> [ 1.  1. -1.  1.]\n",
      "[-1  1  1 -1  1 -1 -1  1] -> [ 1. -1.  1.  1.]\n",
      "[ 1 -1 -1 -1  1 -1  1  1] -> [ 1.  1.  1. -1.]\n",
      "[ 1 -1 -1  1 -1  1 -1  1] -> [-1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# 8->4 binary mapping\n",
    "noise = 0.\n",
    "n_samples = 100\n",
    "s = np.array([[1,0,1,0,0,1,1,0],\n",
    "                         [0,1,0,1,0,1,0,1],\n",
    "                         [0,1,1,0,1,0,0,1],\n",
    "                         [1,0,0,0,1,0,1,1],\n",
    "                         [1,0,0,1,0,1,0,1]], dtype=float)\n",
    "e = np.array([[0,1,1,1],[1,1,0,1],[1,0,1,1],[1,1,1,0],[0,0,0,0]])\n",
    "s = s*2. - 1.\n",
    "e = e*2. - 1.\n",
    "classes = len(s)\n",
    "training_input = []\n",
    "training_output = []\n",
    "r = 0\n",
    "for n in range(n_samples):\n",
    "    r = np.mod(r+1, classes) #r = np.random.randint(classes)\n",
    "    training_input.append(np.array(s[r], dtype=float) + noise*np.random.normal(scale=0.01,size=len(s[r])))\n",
    "    training_output.append(np.array(e[r], dtype=float))\n",
    "\n",
    "training_input = torch.tensor(training_input).float().to(device)\n",
    "training_output = torch.tensor(training_output).float().to(device)\n",
    "train = [training_input, training_output]\n",
    "\n",
    "n_test_samples = 100\n",
    "test_input = []\n",
    "test_output = []\n",
    "r = 0\n",
    "for n in range(n_test_samples):\n",
    "    r = np.mod(r+1, classes) #np.random.randint(classes)\n",
    "    test_input.append(np.array(s[r], dtype=float) + noise*np.random.normal(scale=0.01,size=len(s[r])))\n",
    "    test_output.append(np.array(e[r], dtype=float))\n",
    "\n",
    "test_input = torch.tensor(test_input).float().to(device)\n",
    "test_output = torch.tensor(test_output).float().to(device)\n",
    "test = [test_input, test_output]\n",
    "\n",
    "for x, t in zip(s,e):\n",
    "    print(str(np.array(x,dtype=int))+' -> '+str(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "net = NN.NeuralNetwork()\n",
    "net.AddLayer(Layer.InputPELayer(n=8))\n",
    "# net.AddLayer(Layer.PELayer(n=7))\n",
    "# net.Connect(0, 1)\n",
    "# net.AddLayer(Layer.PELayer(n=6))\n",
    "# net.Connect(1,2)\n",
    "# net.AddLayer(Layer.TopPELayer(n=4))\n",
    "# net.Connect(2,3)\n",
    "# net.ConnectNextLayer(Layer.InputPELayer(n=8))\n",
    "net.ConnectNextLayer(Layer.PELayer(n=7))\n",
    "net.ConnectNextLayer(Layer.PELayer(n=6))\n",
    "net.ConnectNextLayer(Layer.TopPELayer(n=4))\n",
    "net.layers[-1].sigma = Layer.tanh\n",
    "net.layers[-1].sigma_p = Layer.tanh_p\n",
    "net.SetTau(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Polar Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_theta = 4\n",
    "n_rho = 3\n",
    "s = []\n",
    "e = []\n",
    "#for theta in np.linspace(2.*np.pi/(n_theta+2.), 2.*np.pi*(n_theta+1.)/(n_theta+2.), n_theta, endpoint=True):\n",
    "for theta in np.linspace(-1., 1, n_theta+1, endpoint=False):\n",
    "    if theta != -1.:\n",
    "        theta_radians = theta*np.pi\n",
    "        for rho in np.linspace(0., 1., n_rho+1, endpoint=False):\n",
    "            if rho != 0.:\n",
    "                rho2 = rho - 0.5\n",
    "                e.append([rho2, theta])\n",
    "                x = rho*np.cos(theta_radians)\n",
    "                y = rho*np.sin(theta_radians)\n",
    "                s.append([x,y])\n",
    "e = np.array(e)\n",
    "s = np.array(s)\n",
    "#print(e)\n",
    "#print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "training_samples = 100\n",
    "r = 0\n",
    "training_input = []\n",
    "training_output = []\n",
    "for n in range(training_samples):\n",
    "    r = np.mod(r+1, len(s)) #r = np.random.randint(classes)\n",
    "    training_input.append(np.array(s[r,:], dtype=float) )#+ noise*np.random.normal(scale=0.01,size=len(s[r,:])))\n",
    "    training_output.append(np.array(e[r,:], dtype=float))\n",
    "\n",
    "training_input = torch.tensor(training_input).float().to(device)\n",
    "training_output = torch.tensor(training_output).float().to(device)\n",
    "train = [training_input, training_output]\n",
    "\n",
    "n_test_samples = 100\n",
    "test_input = []\n",
    "test_output = []\n",
    "r = 0\n",
    "for n in range(n_test_samples):\n",
    "    r = np.mod(r+1, len(s)) #r = np.random.randint(classes)\n",
    "    test_input.append(np.array(s[r,:], dtype=float) )#+ noise*np.random.normal(scale=0.01,size=len(s[r,:])))\n",
    "    test_output.append(np.array(e[r,:], dtype=float))\n",
    "\n",
    "test_input = torch.tensor(test_input).float().to(device)\n",
    "test_output = torch.tensor(test_output).float().to(device)\n",
    "test = [test_input, test_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAC7CAYAAABhEzkiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109dd9cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1); plt.plot(s[:,0], s[:,1], 'b.'); plt.axis('square');\n",
    "plt.subplot(1,2,2); plt.plot(e[:,0], e[:,1], 'b.'); plt.axis('square');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "net = NN.NeuralNetwork()\n",
    "net.AddLayer(Layer.InputPELayer(n=2)) # 0\n",
    "net.AddLayer(Layer.PELayer(n=6))      # 1\n",
    "net.AddLayer(Layer.PELayer(n=8))      # 2\n",
    "net.AddLayer(Layer.TopPELayer(n=10))  # 3 (augmented)\n",
    "net.AddLayer(Layer.TopPELayer(n=2))   # 4\n",
    "net.Connect(0,1)\n",
    "net.Connect(1,2)\n",
    "net.Connect(2,3)\n",
    "net.Connect(2,4)\n",
    "net.layers[3].sigma = Layer.tanh\n",
    "net.layers[3].sigma_p = Layer.tanh_p\n",
    "net.layers[3].SetFF()  # Augmenting layers have no upper input\n",
    "net.layers[4].sigma = Layer.tanh\n",
    "net.layers[4].sigma_p = Layer.tanh_p\n",
    "net.SetTau(0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "net = NN.NeuralNetwork()\n",
    "net.AddLayer(Layer.InputPELayer(n=2)) # 0\n",
    "net.AddLayer(Layer.PELayer(n=50))     # 3\n",
    "net.AddLayer(Layer.TopPELayer(n=2))   # 4\n",
    "net.Connect(0,1)\n",
    "net.Connect(1,2)\n",
    "net.layers[-1].sigma = Layer.tanh\n",
    "net.layers[-1].sigma_p = Layer.tanh_p\n",
    "net.SetTau(0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b2f7c532b74aa9b7cc80764f9f00da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 11.584635972976685\n"
     ]
    }
   ],
   "source": [
    "train_shuffle = list(zip(train[0],train[1]))\n",
    "batch_size = 10\n",
    "net.learning_tau = torch.tensor(batch_size).float().to(device)\n",
    "epochs = 8\n",
    "fp = FloatProgress(min=0,max=epochs*len(train_shuffle))\n",
    "display(fp)\n",
    "T = 3.\n",
    "start_time = time.time()\n",
    "for k in range(epochs):\n",
    "    np.random.shuffle(train_shuffle)\n",
    "    unzip = list(zip(*train_shuffle))\n",
    "    batches = NN.MakeBatches(unzip[0], unzip[1], batch_size)\n",
    "    for x in batches:\n",
    "        net.Reset()\n",
    "        net.Infer(T, x[0], x[1])\n",
    "        fp.value += batch_size\n",
    "end_time = time.time()\n",
    "print('Total time: '+str(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.Save('bin8-5.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = NN.NeuralNetwork()\n",
    "net.Load('bin8-5.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.Reset()\n",
    "yy = net.Predict(10., train[0])\n",
    "y_true = train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9590,  0.0070,  0.0090,  0.0140,  0.0110],\n",
      "        [ 0.0070,  0.9540,  0.0150,  0.0060,  0.0180],\n",
      "        [ 0.0090,  0.0130,  0.9590,  0.0130,  0.0060],\n",
      "        [ 0.0140,  0.0070,  0.0130,  0.9570,  0.0100],\n",
      "        [ 0.0120,  0.0230,  0.0050,  0.0100,  0.9500],\n",
      "        [ 0.9590,  0.0070,  0.0090,  0.0140,  0.0110],\n",
      "        [ 0.0070,  0.9540,  0.0150,  0.0060,  0.0180],\n",
      "        [ 0.0090,  0.0130,  0.9590,  0.0130,  0.0060],\n",
      "        [ 0.0140,  0.0070,  0.0130,  0.9570,  0.0100],\n",
      "        [ 0.0120,  0.0230,  0.0050,  0.0100,  0.9500]])\n",
      "tensor([[ 1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.],\n",
      "        [ 1.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  1.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  1.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "print(np.round(yy[:10],decimals=3))\n",
    "print(y_true[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10e203320>,\n",
       " <matplotlib.lines.Line2D at 0x10e1aacf8>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a1da080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(yy[:,0]), np.array(yy[:,1]),'b.', np.array(y_true[:,0]), np.array(y_true[:,1]),'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.Reset()\n",
    "yy = net.Generate(10., test[1])\n",
    "y_true = test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  0.,  1.,  0.,  0.])\n",
      "tensor([-1.0694,  1.0690,  0.9980, -0.9760,  1.1230, -1.1234, -1.0366,\n",
      "         1.0200])\n",
      "tensor([-1.,  1.,  1., -1.,  1., -1., -1.,  1.])\n"
     ]
    }
   ],
   "source": [
    "idx = 7\n",
    "print(test[1][idx])\n",
    "print(yy[idx])\n",
    "print(y_true[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0731,  0.0255,  0.1281,  0.7320,  0.0413],\n",
      "        [ 0.0930,  0.0655,  0.1397,  0.6663,  0.0354],\n",
      "        [ 0.0738,  0.1540,  0.7594,  0.0093,  0.0035],\n",
      "        [ 0.1176,  0.0130,  0.1431,  0.7110,  0.0153],\n",
      "        [ 0.0778,  0.0362,  0.1060,  0.7504,  0.0296],\n",
      "        [ 0.2225,  0.0267,  0.0780,  0.6637,  0.0091],\n",
      "        [ 0.7609,  0.0103,  0.0708,  0.0543,  0.1038],\n",
      "        [ 0.7558,  0.0114,  0.0109,  0.1828,  0.0391],\n",
      "        [ 0.0866,  0.0272,  0.0732,  0.7665,  0.0464],\n",
      "        [ 0.1820,  0.0777,  0.7241,  0.0110,  0.0053],\n",
      "        [ 0.1225,  0.0244,  0.0161,  0.0208,  0.8163],\n",
      "        [ 0.0948,  0.0390,  0.1569,  0.6444,  0.0650],\n",
      "        [ 0.0747,  0.0553,  0.0829,  0.7534,  0.0337],\n",
      "        [ 0.0867,  0.0400,  0.1195,  0.7042,  0.0496],\n",
      "        [ 0.1035,  0.0851,  0.7673,  0.0311,  0.0130],\n",
      "        [ 0.7433,  0.0139,  0.0334,  0.1411,  0.0682],\n",
      "        [ 0.2185,  0.0341,  0.0984,  0.6277,  0.0212],\n",
      "        [ 0.0928,  0.1075,  0.7412,  0.0433,  0.0153],\n",
      "        [ 0.0557,  0.0538,  0.0717,  0.7969,  0.0218],\n",
      "        [ 0.2235,  0.0240,  0.7510,  0.0009,  0.0005],\n",
      "        [ 0.1097,  0.7540,  0.0617,  0.0225,  0.0521],\n",
      "        [ 0.0916,  0.0550,  0.0475,  0.7764,  0.0296],\n",
      "        [ 0.0508,  0.0167,  0.1254,  0.7768,  0.0303],\n",
      "        [ 0.1611,  0.0714,  0.0547,  0.6978,  0.0150],\n",
      "        [ 0.1172,  0.0280,  0.0905,  0.7473,  0.0170],\n",
      "        [ 0.1091,  0.0298,  0.0245,  0.0242,  0.8124],\n",
      "        [ 0.0579,  0.1062,  0.7546,  0.0692,  0.0121],\n",
      "        [ 0.1476,  0.0461,  0.0682,  0.7032,  0.0348],\n",
      "        [ 0.1593,  0.0757,  0.7418,  0.0154,  0.0079],\n",
      "        [ 0.8403,  0.0197,  0.0638,  0.0555,  0.0207],\n",
      "        [ 0.7794,  0.0119,  0.0952,  0.0756,  0.0379],\n",
      "        [ 0.0267,  0.8195,  0.0869,  0.0264,  0.0405],\n",
      "        [ 0.1339,  0.0764,  0.1105,  0.6728,  0.0063],\n",
      "        [ 0.1041,  0.0419,  0.0689,  0.7628,  0.0223],\n",
      "        [ 0.0609,  0.0170,  0.1070,  0.7813,  0.0338],\n",
      "        [ 0.1228,  0.0170,  0.1236,  0.7231,  0.0135],\n",
      "        [ 0.0680,  0.1064,  0.7693,  0.0420,  0.0143],\n",
      "        [ 0.1638,  0.0126,  0.8140,  0.0061,  0.0034],\n",
      "        [ 0.0725,  0.0261,  0.1471,  0.6829,  0.0715],\n",
      "        [ 0.0936,  0.1040,  0.7364,  0.0494,  0.0166],\n",
      "        [ 0.1798,  0.0319,  0.0816,  0.6974,  0.0093],\n",
      "        [ 0.1199,  0.0119,  0.1214,  0.7344,  0.0124],\n",
      "        [ 0.1045,  0.0505,  0.1295,  0.6767,  0.0387],\n",
      "        [ 0.7627,  0.0233,  0.0715,  0.1169,  0.0255],\n",
      "        [ 0.7969,  0.0182,  0.1475,  0.0192,  0.0180],\n",
      "        [ 0.0831,  0.0338,  0.0785,  0.7685,  0.0361],\n",
      "        [ 0.1154,  0.0475,  0.1407,  0.6852,  0.0112],\n",
      "        [ 0.0448,  0.0434,  0.0365,  0.0692,  0.8061],\n",
      "        [ 0.1345,  0.0648,  0.0596,  0.7199,  0.0213],\n",
      "        [ 0.7146,  0.0301,  0.0420,  0.1739,  0.0394],\n",
      "        [ 0.0531,  0.0391,  0.1575,  0.7181,  0.0323],\n",
      "        [ 0.1457,  0.0226,  0.0870,  0.7332,  0.0115],\n",
      "        [ 0.6771,  0.0170,  0.0495,  0.0653,  0.1911],\n",
      "        [ 0.0706,  0.8186,  0.0502,  0.0273,  0.0332],\n",
      "        [ 0.0848,  0.0311,  0.1191,  0.7303,  0.0347],\n",
      "        [ 0.1853,  0.0340,  0.0829,  0.6861,  0.0118],\n",
      "        [ 0.0393,  0.7609,  0.0869,  0.0544,  0.0585],\n",
      "        [ 0.7133,  0.0282,  0.0248,  0.0989,  0.1348],\n",
      "        [ 0.0350,  0.8113,  0.0569,  0.0493,  0.0475],\n",
      "        [ 0.8078,  0.0234,  0.0909,  0.0571,  0.0208],\n",
      "        [ 0.0847,  0.0406,  0.0348,  0.0271,  0.8127],\n",
      "        [ 0.1501,  0.1016,  0.7446,  0.0028,  0.0010],\n",
      "        [ 0.1816,  0.0796,  0.0587,  0.6517,  0.0284],\n",
      "        [ 0.1951,  0.0284,  0.1688,  0.5940,  0.0136],\n",
      "        [ 0.1099,  0.0547,  0.1197,  0.6856,  0.0302],\n",
      "        [ 0.1944,  0.0294,  0.0484,  0.7196,  0.0083],\n",
      "        [ 0.1270,  0.1395,  0.7183,  0.0115,  0.0037],\n",
      "        [ 0.1510,  0.0277,  0.0699,  0.7230,  0.0284],\n",
      "        [ 0.1192,  0.0281,  0.1400,  0.6887,  0.0240],\n",
      "        [ 0.0980,  0.0847,  0.0520,  0.7358,  0.0295],\n",
      "        [ 0.1422,  0.0378,  0.8120,  0.0054,  0.0026],\n",
      "        [ 0.0534,  0.7502,  0.0878,  0.0481,  0.0605],\n",
      "        [ 0.8303,  0.0178,  0.0410,  0.0607,  0.0501],\n",
      "        [ 0.1561,  0.0911,  0.7144,  0.0276,  0.0107],\n",
      "        [ 0.7844,  0.0113,  0.0979,  0.0938,  0.0126],\n",
      "        [ 0.2307,  0.0360,  0.0448,  0.6806,  0.0078],\n",
      "        [ 0.1688,  0.0519,  0.0352,  0.7234,  0.0207],\n",
      "        [ 0.7233,  0.0241,  0.0378,  0.1805,  0.0344],\n",
      "        [ 0.0932,  0.0270,  0.1136,  0.7405,  0.0257],\n",
      "        [ 0.0328,  0.0494,  0.1026,  0.7712,  0.0440],\n",
      "        [ 0.0495,  0.0471,  0.0606,  0.0340,  0.8088],\n",
      "        [ 0.1073,  0.0313,  0.1066,  0.7286,  0.0263],\n",
      "        [ 0.1750,  0.0217,  0.0561,  0.7399,  0.0073],\n",
      "        [ 0.1427,  0.0983,  0.0227,  0.0443,  0.6919],\n",
      "        [ 0.0946,  0.0720,  0.0578,  0.7532,  0.0223],\n",
      "        [ 0.0979,  0.1285,  0.7463,  0.0203,  0.0070],\n",
      "        [ 0.7416,  0.0145,  0.0331,  0.1424,  0.0683],\n",
      "        [ 0.1249,  0.0428,  0.1034,  0.6980,  0.0307],\n",
      "        [ 0.0869,  0.0254,  0.1535,  0.6975,  0.0366],\n",
      "        [ 0.0991,  0.0433,  0.1115,  0.7260,  0.0202],\n",
      "        [ 0.2276,  0.0178,  0.7392,  0.0104,  0.0050],\n",
      "        [ 0.0828,  0.0693,  0.0934,  0.7287,  0.0259],\n",
      "        [ 0.0740,  0.1043,  0.7675,  0.0435,  0.0108],\n",
      "        [ 0.1102,  0.1064,  0.7471,  0.0273,  0.0089],\n",
      "        [ 0.1176,  0.0560,  0.0925,  0.7090,  0.0248],\n",
      "        [ 0.7803,  0.0185,  0.0666,  0.1018,  0.0328],\n",
      "        [ 0.1952,  0.0401,  0.0367,  0.7087,  0.0193],\n",
      "        [ 0.1099,  0.0169,  0.1414,  0.7169,  0.0150],\n",
      "        [ 0.0167,  0.7086,  0.0921,  0.0840,  0.0986],\n",
      "        [ 0.0536,  0.0902,  0.0602,  0.7742,  0.0218]])\n"
     ]
    }
   ],
   "source": [
    "net.Reset()\n",
    "yy = net.Predict(10., rand[0])\n",
    "print(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooled 0.0%\n",
      "Max Confidence   tensor(0.8403)\n",
      "Average Confidence tensor(36.9585)\n"
     ]
    }
   ],
   "source": [
    "fooled_count = 0\n",
    "max_confidence = 0.\n",
    "total_confidence = 0.\n",
    "for yyy in yy:\n",
    "    est_class = np.argmax(yyy)\n",
    "    confidence = yyy[est_class]\n",
    "    if confidence>max_confidence:\n",
    "        max_confidence = confidence\n",
    "        #max_confidence_idx = idx\n",
    "        #max_confidence_class = est_class\n",
    "        #best_fooler = random_x\n",
    "        #print(str(max_confidence_class))\n",
    "    if confidence>0.95:\n",
    "        fooled_count += 1\n",
    "        #print(str(np.round(random_x,3))+' '+str(s[est_class])+' '+str(np.round(sm,3)))\n",
    "        \n",
    "    total_confidence += yyy[est_class]\n",
    "    \n",
    "print('Fooled ' + str(float(fooled_count*100.)/len(rand)) + '%')\n",
    "print('Max Confidence   ' + str(max_confidence))\n",
    "print('Average Confidence ' + str(total_confidence/len(rand)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Test for binary strings dataset\n",
    "fail = 0\n",
    "for x,t in zip(yy, y_true):\n",
    "    if np.isnan(t).any() or torch.min(x*t).le(0.):\n",
    "        fail += 1\n",
    "n_trials = float(len(y_true))\n",
    "print('Accuracy '+str((n_trials-fail)/n_trials*100.)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "# Test for polar clusters dataset\n",
    "fail = 0\n",
    "for x,t in zip(yy, y_true):\n",
    "    if np.isnan(t).any() or torch.max(abs(x-t)).ge(0.2):\n",
    "        fail += 1\n",
    "n_trials = float(len(test[0]))\n",
    "print('Accuracy '+str((n_trials-fail)/n_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1699,  0.1597,  0.1946,  0.3365,  0.1393])\n",
      "tensor([ 0.,  1.,  0.,  0.,  0.])\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(test[0]))\n",
    "net.Reset()\n",
    "print(net.Predict(5., test[0][idx]))\n",
    "print(test[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net2 = NN.NeuralNetwork()\n",
    "net2.Load('blah.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 7])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(net2.W[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([nan., nan., nan., nan., nan.])\n",
      "tensor([ 0.,  1.,  0.,  0.,  0.])\n"
     ]
    }
   ],
   "source": [
    "net2.Reset()\n",
    "print(net2.Predict(5., test[0][idx]))\n",
    "print(test[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7])\n",
      "torch.Size([7, 8])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 7])\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(net2.layers[1].dvdt))\n",
    "print(np.shape(net2.W[0]))\n",
    "print(np.shape(net2.layers[0].e))\n",
    "print(np.shape(net2.M[0]))\n",
    "print(np.shape(net2.layers[1].v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7])\n",
      "torch.Size([7, 8])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 7])\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(net.layers[1].dvdt))\n",
    "print(np.shape(net.W[0]))\n",
    "print(np.shape(net.layers[0].e))\n",
    "print(np.shape(net.M[0]))\n",
    "print(np.shape(net.layers[1].v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5916, -0.5986, -0.8456, -0.7550,  0.8802, -0.8882,  0.5235,\n",
      "         1.1115])\n",
      "tensor([ 1., -1., -1., -1.,  1., -1.,  1.,  1.])\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(len(test[1]))\n",
    "xx = net.Generate(10., test[1][idx])\n",
    "print(xx)\n",
    "print(test[0][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "print(np.round(x_true[idx:idx+5],0)-np.round(x_est[idx:idx+5],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. -1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9986,  0.9992, -0.9991,  0.9972], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 58\n",
    "print(train[1][idx])\n",
    "net.Predict(10., train[0][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {
    "8136bdaf4a3a4a7a8ebc121258db3244": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "df58eb1fe74745dc82a439a5c68f9390": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
